{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Auto Claims Solution"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azureml.core\n",
        "from azureml.core import Dataset\n",
        "from azureml.core import Workspace\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to use Azure ML 1.30.0 to work with dp100ws\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1624735358324
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to default datastore**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_ds = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624735364289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create folders for the solutions**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for the pipeline step files\n",
        "pipeline_folder = 'auto_claims_pipeline'\n",
        "service_folder = 'auto_claims_service'\n",
        "\n",
        "os.makedirs(pipeline_folder, exist_ok=True)\n",
        "os.makedirs(service_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624739264559
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the dataset**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = ws.datasets.get('auto claims').to_pandas_dataframe()\r\n",
        "df[:3]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "          ID KIDSDRIV    BIRTH AGE HOMEKIDS YOJ   INCOME PARENT1  HOME_VAL  \\\n0   63581743        0  16MAR39  60        0  11  $67,349      No        $0   \n1  132761049        0  21JAN56  43        0  11  $91,449      No  $257,252   \n2  921317019        0  18NOV51  48        0  11  $52,881      No        $0   \n\n  MSTATUS  ... CAR_TYPE RED_CAR OLDCLAIM CLM_FREQ REVOKED MVR_PTS CLM_AMT  \\\n0    z_No  ...  Minivan     yes   $4,461        2      No       3      $0   \n1    z_No  ...  Minivan     yes       $0        0      No       0      $0   \n2    z_No  ...      Van     yes       $0        0      No       2      $0   \n\n  CAR_AGE CLAIM_FLAG           URBANICITY  \n0      18          0  Highly Urban/ Urban  \n1       1          0  Highly Urban/ Urban  \n2      10          0  Highly Urban/ Urban  \n\n[3 rows x 27 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>KIDSDRIV</th>\n      <th>BIRTH</th>\n      <th>AGE</th>\n      <th>HOMEKIDS</th>\n      <th>YOJ</th>\n      <th>INCOME</th>\n      <th>PARENT1</th>\n      <th>HOME_VAL</th>\n      <th>MSTATUS</th>\n      <th>...</th>\n      <th>CAR_TYPE</th>\n      <th>RED_CAR</th>\n      <th>OLDCLAIM</th>\n      <th>CLM_FREQ</th>\n      <th>REVOKED</th>\n      <th>MVR_PTS</th>\n      <th>CLM_AMT</th>\n      <th>CAR_AGE</th>\n      <th>CLAIM_FLAG</th>\n      <th>URBANICITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63581743</td>\n      <td>0</td>\n      <td>16MAR39</td>\n      <td>60</td>\n      <td>0</td>\n      <td>11</td>\n      <td>$67,349</td>\n      <td>No</td>\n      <td>$0</td>\n      <td>z_No</td>\n      <td>...</td>\n      <td>Minivan</td>\n      <td>yes</td>\n      <td>$4,461</td>\n      <td>2</td>\n      <td>No</td>\n      <td>3</td>\n      <td>$0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>132761049</td>\n      <td>0</td>\n      <td>21JAN56</td>\n      <td>43</td>\n      <td>0</td>\n      <td>11</td>\n      <td>$91,449</td>\n      <td>No</td>\n      <td>$257,252</td>\n      <td>z_No</td>\n      <td>...</td>\n      <td>Minivan</td>\n      <td>yes</td>\n      <td>$0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>0</td>\n      <td>$0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>921317019</td>\n      <td>0</td>\n      <td>18NOV51</td>\n      <td>48</td>\n      <td>0</td>\n      <td>11</td>\n      <td>$52,881</td>\n      <td>No</td>\n      <td>$0</td>\n      <td>z_No</td>\n      <td>...</td>\n      <td>Van</td>\n      <td>yes</td>\n      <td>$0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>2</td>\n      <td>$0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 27 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624735401756
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Preprocessing Script File in the pipeline folder**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $pipeline_folder/preprocessing.py\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "def format_data(\r\n",
        "    dataframe, \r\n",
        "    currency_columns=['HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT','INCOME'],\r\n",
        "    to_clean = ['EDUCATION','OCCUPATION','MSTATUS','GENDER','CAR_TYPE','URBANICITY']\r\n",
        "    ):\r\n",
        "\r\n",
        "    df = dataframe.copy()\r\n",
        "    for c in currency_columns:\r\n",
        "        if c in df.columns:\r\n",
        "            df[c] = df[c].str.replace('$','').str.replace(',','').astype(float)\r\n",
        "\r\n",
        "    for col in to_clean:\r\n",
        "        if col in df.columns:\r\n",
        "            df[col] = df[col].str.replace('z_','').str.replace('<','')\r\n",
        "\r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "def clean_categoricals(dataframe):\r\n",
        "    df = dataframe.copy()\r\n",
        "\r\n",
        "    categorical_map = {\r\n",
        "        'PARENT1': {'No': 0, 'Yes': 1}, \r\n",
        "        'MSTATUS': {'Yes': 0, 'No': 1},\r\n",
        "        'GENDER': {'F': 0, 'M': 1}, \r\n",
        "        'EDUCATION': {'High School': 0, 'Bachelors': 1, 'Masters': 2, 'PhD': 3}, \r\n",
        "        'CAR_USE': {'Private': 0, 'Commercial': 1}, \r\n",
        "        'CAR_TYPE': {'SUV': 0, 'Minivan': 1, 'Pickup': 2, 'Sports Car': 3, 'Van': 4, 'Panel Truck': 5}, \r\n",
        "        'RED_CAR': {'no': 0, 'yes': 1},\r\n",
        "        'REVOKED': {'No': 0, 'Yes': 1}, \r\n",
        "        'URBANICITY': {'Highly Urban/ Urban': 0, 'Highly Rural/ Rural': 1},\r\n",
        "        'OCCUPATION': {'Blue Collar': 0, 'Clerical': 1, 'Professional': 2, 'Manager': 3, 'Lawyer': 4, 'Student': 5, 'Home Maker': 6, 'Doctor': 7}\r\n",
        "    }\r\n",
        "\r\n",
        "    for k,v in categorical_map.items():\r\n",
        "        df[k] = df[k].replace(v)\r\n",
        "\r\n",
        "    return df\r\n",
        "\r\n",
        "def clean_numericals(dataframe, numerical_columns=['AGE', 'INCOME','BLUEBOOK','TIF','OLDCLAIM','HOME_VAL']):\r\n",
        "    df = dataframe.copy()\r\n",
        "\r\n",
        "    for c in numerical_columns:\r\n",
        "        df[c] = df[c].apply(lambda x: np.log(x) + 1).replace([np.inf,-np.inf],1)\r\n",
        "\r\n",
        "    return df\r\n",
        "\r\n",
        "def preprocessing(data,inference=False):\r\n",
        "    columns = ['ID','KIDSDRIV','BIRTH','AGE','HOMEKIDS','YOJ','INCOME','PARENT1','HOME_VAL','MSTATUS','GENDER','EDUCATION','OCCUPATION','TRAVTIME','CAR_USE','BLUEBOOK','TIF','CAR_TYPE','RED_CAR','OLDCLAIM','CLM_FREQ','REVOKED','MVR_PTS','CLM_AMT','CAR_AGE','CLAIM_FLAG','URBANICITY']\r\n",
        "    to_drop = ['ID','YOJ','BIRTH']\r\n",
        "    targets = ['CLAIM_FLAG','CLM_FREQ','CLM_AMT']\r\n",
        "\r\n",
        "    if inference:\r\n",
        "        columns = [x for x in columns if x not in targets]\r\n",
        "\r\n",
        "    if isinstance(data,np.ndarray):\r\n",
        "        data = pd.DataFrame(data,columns=columns)\r\n",
        "\r\n",
        "    data = data.drop(to_drop,axis=1)\r\n",
        "    data = format_data(dataframe=data)\r\n",
        "    data = clean_categoricals(dataframe=data).astype(float)\r\n",
        "    data = clean_numericals(dataframe=data)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    return data\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting auto_claims_pipeline/preprocessing.py\n"
          ]
        }
      ],
      "execution_count": 125,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624744725141
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copy the preprocessing script in the service folder**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp $pipeline_folder/preprocessing.py $service_folder/preprocessing.py"
      ],
      "outputs": [],
      "execution_count": 126,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the preprocessing function iniside the data preparation step**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_data.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from preprocessing import preprocessing\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "df = preprocessing(df)\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(df))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove nulls\n",
        "df = df.dropna()\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(df))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "df.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting auto_claims_pipeline/prep_data.py\n"
          ]
        }
      ],
      "execution_count": 127,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and register models on the processed data**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_model.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, PoissonRegressor, GammaRegressor\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "lr_target = 'CLAIM_FLAG'\n",
        "po_target = 'CLM_FREQ'\n",
        "gm_target = 'CLM_AMT'\n",
        "\n",
        "target_cols = [lr_target, po_target, gm_target]\n",
        "\n",
        "# Split data into training set and test set\n",
        "train, test = train_test_split(df, test_size=0.33, random_state=123, stratify=df[lr_target])\n",
        "\n",
        "train_no_claims = train[train[gm_target] > 0].copy()\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(train.drop(target_cols,axis=1),train[lr_target])\n",
        "\n",
        "po_model = PoissonRegressor()\n",
        "po_model.fit(train_no_claims.drop(target_cols,axis=1),train_no_claims[po_target])\n",
        "\n",
        "gm_model = GammaRegressor()\n",
        "gm_model.fit(train_no_claims.drop(target_cols,axis=1),train_no_claims[gm_target])\n",
        "\n",
        "lr_pred = lr_model.predict_proba(test.drop(target_cols,axis=1))[:,1]\n",
        "po_pred = lr_model.predict(test.drop(target_cols,axis=1))\n",
        "gm_pred = lr_model.predict(test.drop(target_cols,axis=1))\n",
        "\n",
        "\n",
        "loss_cost = (lr_pred * po_pred) * gm_pred\n",
        "\n",
        "rmse = metrics.mean_squared_error(test[gm_target],loss_cost,squared=False)\n",
        "\n",
        "run.log('RMSE', np.float(rmse))\n",
        "\n",
        "\n",
        "model = dict(\n",
        "    lr_model=lr_model,\n",
        "    po_model=po_model,\n",
        "    gm_model=gm_model\n",
        ")\n",
        "\n",
        "model_file = os.path.join('outputs', 'zip_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'auto_claims_zip_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'RMSE': np.float(rmse)})\n",
        "\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting auto_claims_pipeline/train_model.py\n"
          ]
        }
      ],
      "execution_count": 128,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to a compute cluster or create one if does not exists**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"dp100cc\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n"
          ]
        }
      ],
      "execution_count": 129,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624744756563
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write the environment file for the training pipeline**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $pipeline_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting auto_claims_pipeline/experiment_env.yml\n"
          ]
        }
      ],
      "execution_count": 130,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create environment using the conda yaml**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", pipeline_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run configuration created.\n"
          ]
        }
      ],
      "execution_count": 131,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624744757334
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confiigure the pipeline steps**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "auto_claims_dataset = ws.datasets.get(\"auto claims\")\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\r\n",
        "                                source_directory = pipeline_folder,\r\n",
        "                                script_name = \"prep_data.py\",\r\n",
        "                                arguments = ['--input-data', auto_claims_dataset.as_named_input('raw_data'),\r\n",
        "                                             '--prepped-data', prepped_data],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "# Step 2, run the training script\r\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\r\n",
        "                                source_directory = pipeline_folder,\r\n",
        "                                script_name = \"train_model.py\",\r\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline steps defined\n"
          ]
        }
      ],
      "execution_count": 132,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624744757876
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload and run the pipeline**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'auto-claims-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline is built.\n",
            "Created step Prepare Data [28b2524c][16a51b59-fd08-4b55-aa12-9145410ab855], (This step will run and generate new outputs)Created step Train and Register Model [5a16bbd6][118b1f4d-5c32-457e-abfa-959035e7aec6], (This step will run and generate new outputs)\n",
            "\n",
            "Submitted PipelineRun f3abba4d-ed34-46c7-af13-b138ff1ae88b\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f3abba4d-ed34-46c7-af13-b138ff1ae88b?wsid=/subscriptions/d1cbef34-81e9-4f99-9cf3-8d36f1255e04/resourcegroups/dp100/workspaces/dp100ws&tid=37219092-bab7-4671-af41-d7ded0486bc7\n",
            "Pipeline submitted for execution.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b8eb861fd07447ba274cde311458a9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/f3abba4d-ed34-46c7-af13-b138ff1ae88b?wsid=/subscriptions/d1cbef34-81e9-4f99-9cf3-8d36f1255e04/resourcegroups/dp100/workspaces/dp100ws&tid=37219092-bab7-4671-af41-d7ded0486bc7\", \"run_id\": \"f3abba4d-ed34-46c7-af13-b138ff1ae88b\", \"run_properties\": {\"run_id\": \"f3abba4d-ed34-46c7-af13-b138ff1ae88b\", \"created_utc\": \"2021-06-26T21:59:22.790309Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-06-26T22:06:15.119163Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f3abba4d-ed34-46c7-af13-b138ff1ae88b/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=CV8BLJS1pbR1H%2BkZ9ZWw7bPLLIca%2Bl%2Fb%2Fcm2CwyZ9lg%3D&st=2021-06-26T21%3A49%3A45Z&se=2021-06-27T05%3A59%3A45Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f3abba4d-ed34-46c7-af13-b138ff1ae88b/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=cyYyOOLp7eGvJiXN5MXx8DO0TBaUsEqy4ZyPhywoHxE%3D&st=2021-06-26T21%3A49%3A45Z&se=2021-06-27T05%3A59%3A45Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f3abba4d-ed34-46c7-af13-b138ff1ae88b/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=GH2nelx01fTK20iV5lDUNAYdJeuCn7NB3pmrwhzrru4%3D&st=2021-06-26T21%3A49%3A45Z&se=2021-06-27T05%3A59%3A45Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:06:52\", \"run_number\": \"22\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"715cb5ea-43a5-46ae-b91c-02fa0d9e9440\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-06-26T22:02:34.176879Z\", \"created_time\": \"2021-06-26T21:59:25.230652Z\", \"end_time\": \"2021-06-26T22:05:25.316516Z\", \"duration\": \"0:06:00\", \"run_number\": 23, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-26T21:59:25.230652Z\", \"is_reused\": \"\"}, {\"run_id\": \"f1454c10-0829-445d-aa3e-5d6011809dd0\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-06-26T22:05:38.180853Z\", \"created_time\": \"2021-06-26T22:05:28.829194Z\", \"end_time\": \"2021-06-26T22:06:13.999052Z\", \"duration\": \"0:00:45\", \"run_number\": 24, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-26T22:05:28.829194Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-06-26 21:59:25Z] Submitting 1 runs, first five are: 28b2524c:715cb5ea-43a5-46ae-b91c-02fa0d9e9440\\n[2021-06-26 22:05:28Z] Completing processing run id 715cb5ea-43a5-46ae-b91c-02fa0d9e9440.\\n[2021-06-26 22:05:28Z] Submitting 1 runs, first five are: 5a16bbd6:f1454c10-0829-445d-aa3e-5d6011809dd0\\n[2021-06-26 22:06:14Z] Completing processing run id f1454c10-0829-445d-aa3e-5d6011809dd0.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"80dc45fe\": {\"node_id\": \"80dc45fe\", \"name\": \"Auto Claims\"}}, \"module_nodes\": {\"28b2524c\": {\"node_id\": \"28b2524c\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"715cb5ea-43a5-46ae-b91c-02fa0d9e9440\"}, \"5a16bbd6\": {\"node_id\": \"5a16bbd6\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"f1454c10-0829-445d-aa3e-5d6011809dd0\"}}, \"edges\": [{\"source_node_id\": \"80dc45fe\", \"source_node_name\": \"Auto Claims\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"28b2524c\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"28b2524c\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_22a0f976\", \"dst_node_id\": \"5a16bbd6\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"715cb5ea-43a5-46ae-b91c-02fa0d9e9440\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-06-26T22:02:34.176879Z\", \"created_time\": \"2021-06-26T21:59:25.230652Z\", \"end_time\": \"2021-06-26T22:05:25.316516Z\", \"duration\": \"0:06:00\", \"run_number\": 23, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-26T21:59:25.230652Z\", \"is_reused\": \"\"}, {\"run_id\": \"f1454c10-0829-445d-aa3e-5d6011809dd0\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-06-26T22:05:38.180853Z\", \"created_time\": \"2021-06-26T22:05:28.829194Z\", \"end_time\": \"2021-06-26T22:06:13.999052Z\", \"duration\": \"0:00:45\", \"run_number\": 24, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-26T22:05:28.829194Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.30.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: f3abba4d-ed34-46c7-af13-b138ff1ae88b\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f3abba4d-ed34-46c7-af13-b138ff1ae88b?wsid=/subscriptions/d1cbef34-81e9-4f99-9cf3-8d36f1255e04/resourcegroups/dp100/workspaces/dp100ws&tid=37219092-bab7-4671-af41-d7ded0486bc7\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 715cb5ea-43a5-46ae-b91c-02fa0d9e9440\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/715cb5ea-43a5-46ae-b91c-02fa0d9e9440?wsid=/subscriptions/d1cbef34-81e9-4f99-9cf3-8d36f1255e04/resourcegroups/dp100/workspaces/dp100ws&tid=37219092-bab7-4671-af41-d7ded0486bc7\n",
            "StepRun( Prepare Data ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt\n",
            "========================================================================================================================\n",
            "2021-06-26T22:02:32Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24790 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            "2021-06-26T22:02:33Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/mounts/workspaceblobstore\n",
            "2021-06-26T22:02:33Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
            "2021-06-26T22:02:33Z Starting output-watcher...\n",
            "2021-06-26T22:02:33Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2021-06-26T22:02:33Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
            "2021-06-26T22:02:33Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_fe4afc798de401edfb76dc27a38b1703\n",
            "92473f7ef455: Pulling fs layer\n",
            "fb52bde70123: Pulling fs layer\n",
            "64788f86be3f: Pulling fs layer\n",
            "33f6d5f2e001: Pulling fs layer\n",
            "eeb715f1b6ae: Pulling fs layer\n",
            "fe519cf36537: Pulling fs layer\n",
            "58ff99196c15: Pulling fs layer\n",
            "9b13f06a8eff: Pulling fs layer\n",
            "2d4e93adbf58: Pulling fs layer\n",
            "6ee7c3767844: Pulling fs layer\n",
            "62cfc3ccb8ab: Pulling fs layer\n",
            "4a7af9d757ee: Pulling fs layer\n",
            "9e11d437728f: Pulling fs layer\n",
            "3506c910620f: Pulling fs layer\n",
            "afe6352c52c2: Pulling fs layer\n",
            "45d886309004: Pulling fs layer\n",
            "2ce19e789040: Pulling fs layer\n",
            "f2a2950e1ed4: Pulling fs layer\n",
            "33f6d5f2e001: Waiting\n",
            "eeb715f1b6ae: Waiting\n",
            "fe519cf36537: Waiting\n",
            "58ff99196c15: Waiting\n",
            "9b13f06a8eff: Waiting\n",
            "2d4e93adbf58: Waiting\n",
            "6ee7c3767844: Waiting\n",
            "62cfc3ccb8ab: Waiting\n",
            "4a7af9d757ee: Waiting\n",
            "9e11d437728f: Waiting\n",
            "3506c910620f: Waiting\n",
            "afe6352c52c2: Waiting\n",
            "45d886309004: Waiting\n",
            "2ce19e789040: Waiting\n",
            "f2a2950e1ed4: Waiting\n",
            "64788f86be3f: Verifying Checksum\n",
            "64788f86be3f: Download complete\n",
            "fb52bde70123: Verifying Checksum\n",
            "fb52bde70123: Download complete\n",
            "33f6d5f2e001: Verifying Checksum\n",
            "33f6d5f2e001: Download complete\n",
            "fe519cf36537: Verifying Checksum\n",
            "fe519cf36537: Download complete\n",
            "92473f7ef455: Verifying Checksum\n",
            "92473f7ef455: Download complete\n",
            "58ff99196c15: Verifying Checksum\n",
            "58ff99196c15: Download complete\n",
            "eeb715f1b6ae: Verifying Checksum\n",
            "eeb715f1b6ae: Download complete\n",
            "9b13f06a8eff: Verifying Checksum\n",
            "9b13f06a8eff: Download complete\n",
            "2d4e93adbf58: Verifying Checksum\n",
            "2d4e93adbf58: Download complete\n",
            "62cfc3ccb8ab: Verifying Checksum\n",
            "62cfc3ccb8ab: Download complete\n",
            "6ee7c3767844: Verifying Checksum\n",
            "6ee7c3767844: Download complete\n",
            "4a7af9d757ee: Verifying Checksum\n",
            "4a7af9d757ee: Download complete\n",
            "afe6352c52c2: Verifying Checksum\n",
            "afe6352c52c2: Download complete\n",
            "9e11d437728f: Verifying Checksum\n",
            "9e11d437728f: Download complete\n",
            "45d886309004: Verifying Checksum\n",
            "45d886309004: Download complete\n",
            "2ce19e789040: Verifying Checksum\n",
            "2ce19e789040: Download complete\n",
            "f2a2950e1ed4: Verifying Checksum\n",
            "f2a2950e1ed4: Download complete\n",
            "3506c910620f: Verifying Checksum\n",
            "3506c910620f: Download complete\n",
            "92473f7ef455: Pull complete\n",
            "fb52bde70123: Pull complete\n",
            "64788f86be3f: Pull complete\n",
            "33f6d5f2e001: Pull complete\n",
            "eeb715f1b6ae: Pull complete\n",
            "fe519cf36537: Pull complete\n",
            "58ff99196c15: Pull complete\n",
            "9b13f06a8eff: Pull complete\n",
            "2d4e93adbf58: Pull complete\n",
            "6ee7c3767844: Pull complete\n",
            "62cfc3ccb8ab: Pull complete\n",
            "4a7af9d757ee: Pull complete\n",
            "9e11d437728f: Pull complete\n",
            "3506c910620f: Pull complete\n",
            "afe6352c52c2: Pull complete\n",
            "45d886309004: Pull complete\n",
            "2ce19e789040: Pull complete\n",
            "f2a2950e1ed4: Pull complete\n",
            "Digest: sha256:5224cd9c4e07c9304c90193ab084da3cf8643e81065eef4d81c2c4029c58248c\n",
            "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_fe4afc798de401edfb76dc27a38b1703:latest\n",
            "viennaglobal.azurecr.io/azureml/azureml_fe4afc798de401edfb76dc27a38b1703:latest\n",
            "2021-06-26T22:03:09Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
            "2021-06-26T22:03:09Z Check if container 715cb5ea-43a5-46ae-b91c-02fa0d9e9440_DataSidecar already exist exited with 0, \n",
            "\n",
            "5b93bb2912a358ecc99851e660270a1f5665fa7e3392e083aca730e8010f8232\n",
            "2021-06-26T22:03:19Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            "2021-06-26T22:03:19Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-9fd3d029732920a43dbc8f971ddb6481-43e0fc90ae94f2c1-01 -sshRequired=false] \n",
            "2021/06/26 22:03:19 Starting App Insight Logger for task:  containerSetup\n",
            "2021/06/26 22:03:19 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
            "2021/06/26 22:03:19 Entered ContainerSetupTask - Preparing infiniband\n",
            "2021/06/26 22:03:19 Starting infiniband setup\n",
            "2021/06/26 22:03:19 Python Version found is Python 3.7.9\n",
            "\n",
            "2021/06/26 22:03:19 Returning Python Version as 3.7\n",
            "2021/06/26 22:03:19 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
            "2021/06/26 22:03:19 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
            "2021-06-26T22:03:19Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
            "2021/06/26 22:03:19 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/06/26 22:03:19 Not setting up Infiniband in Container\n",
            "2021/06/26 22:03:19 Not setting up Infiniband in Container\n",
            "2021-06-26T22:03:19Z Not setting up Infiniband in Container\n",
            "2021/06/26 22:03:19 Python Version found is Python 3.7.9\n",
            "\n",
            "2021/06/26 22:03:19 Returning Python Version as 3.7\n",
            "2021/06/26 22:03:19 sshd inside container not required for job, skipping setup.\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt\n",
            "===============================================================================================================\n",
            "[2021-06-26T22:03:20.824637] Entering job preparation.\n",
            "[2021-06-26T22:03:21.563560] Starting job preparation.\n",
            "[2021-06-26T22:03:21.563610] Extracting the control code.\n",
            "[2021-06-26T22:03:21.564332] Starting extract_project.\n",
            "[2021-06-26T22:03:21.564650] Starting to extract zip file.\n",
            "[2021-06-26T22:03:21.581690] Finished extracting zip file.\n",
            "[2021-06-26T22:03:21.584334] Using urllib.request Python 3.0 or later\n",
            "[2021-06-26T22:03:21.584668] Start fetching snapshots.\n",
            "[2021-06-26T22:03:21.584866] Start fetching snapshot.\n",
            "[2021-06-26T22:03:21.585040] Retrieving project from snapshot: aed25108-25f8-4cc4-8e36-acc274b7495a\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 39\n",
            "[2021-06-26T22:03:21.981611] Finished fetching snapshot.\n",
            "[2021-06-26T22:03:21.981648] Finished fetching snapshots.\n",
            "[2021-06-26T22:03:21.981670] Finished extract_project.\n",
            "[2021-06-26T22:03:21.981738] Finished fetching and extracting the control code.\n",
            "[2021-06-26T22:03:21.988513] Start run_history_prep.\n",
            "[2021-06-26T22:03:21.995404] Job preparation is complete.\n",
            "[2021-06-26T22:03:21.995666] Entering Data Context Managers in Sidecar\n",
            "[2021-06-26T22:03:21.996497] Running Sidecar prep cmd...\n",
            "[2021-06-26T22:03:22.379092] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440\n",
            "[2021-06-26T22:03:22.379899] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.28.0 azureml-dataprep==2.16.0. Session id: 2155f37b-12d1-4be3-9636-e8718db7d520. Run id: 715cb5ea-43a5-46ae-b91c-02fa0d9e9440.\n",
            "Processing 'prepped_data'.\n",
            "Mounted prepped_data to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/prepped_data_workspaceblobstore.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set OutputDataset prepped_data's target path to /mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/prepped_data_workspaceblobstore\n",
            "[2021-06-26T22:03:32.196137] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-06-26T22:03:32.558095] Ran Sidecar prep cmd.\n",
            "[2021-06-26T22:03:32.558219] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/06/26 22:04:52 Starting App Insight Logger for task:  runTaskLet\n",
            "2021/06/26 22:04:52 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
            "2021/06/26 22:04:52 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
            "2021/06/26 22:04:52 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
            "[2021-06-26T22:04:52.095121] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['prep_data.py', '--input-data', '65b8a486-3be0-4a2e-9489-df54685f0c78', '--prepped-data', 'DatasetOutputConfig:prepped_data'])\n",
            "Script type = None\n",
            "[2021-06-26T22:04:52.603887] Entering Run History Context Manager.\n",
            "[2021-06-26T22:04:53.286916] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440\n",
            "[2021-06-26T22:04:53.287193] Preparing to call script [prep_data.py] with arguments:['--input-data', '65b8a486-3be0-4a2e-9489-df54685f0c78', '--prepped-data', '$prepped_data']\n",
            "[2021-06-26T22:04:53.287220] After variable expansion, calling script [prep_data.py] with arguments:['--input-data', '65b8a486-3be0-4a2e-9489-df54685f0c78', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/prepped_data_workspaceblobstore']\n",
            "\n",
            "Loading Data...\n",
            "2021/06/26 22:04:57 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "Saving Data...\n",
            "\n",
            "\n",
            "[2021-06-26T22:05:01.501939] The experiment completed successfully. Finalizing run...\n",
            "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
            "2 items cleaning up...\n",
            "Cleanup took 0.13347196578979492 seconds\n",
            "[2021-06-26T22:05:01.771557] Finished context manager injector.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt\n",
            "===============================================================================================================\n",
            "[2021-06-26T22:05:08.379228] Entering job release\n",
            "[2021-06-26T22:05:09.208284] Starting job release\n",
            "[2021-06-26T22:05:09.209294] Logging experiment finalizing status in history service.\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 216\n",
            "[2021-06-26T22:05:09.209845] job release stage : upload_datastore starting...\n",
            "[2021-06-26T22:05:09.216385] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "[2021-06-26T22:05:09.225494] Entering context manager injector.[2021-06-26T22:05:09.225535] job release stage : execute_job_release starting...\n",
            "[2021-06-26T22:05:09.225940] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-06-26T22:05:09.226116] job release stage : copy_batchai_cached_logs completed...\n",
            "\n",
            "[2021-06-26T22:05:09.232501] job release stage : upload_datastore completed...\n",
            "[2021-06-26T22:05:09.324093] job release stage : send_run_telemetry starting...\n",
            "[2021-06-26T22:05:09.339591] get vm size and vm region successfully.\n",
            "[2021-06-26T22:05:09.348030] get compute meta data successfully.\n",
            "[2021-06-26T22:05:09.385645] job release stage : execute_job_release completed...\n",
            "[2021-06-26T22:05:09.468082] post artifact meta request successfully.\n",
            "[2021-06-26T22:05:09.500952] upload compute record artifact successfully.\n",
            "[2021-06-26T22:05:09.501255] job release stage : send_run_telemetry completed...\n",
            "[2021-06-26T22:05:09.501880] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-06-26T22:05:09.502186] Running Sidecar release cmd...\n",
            "[2021-06-26T22:05:09.526105] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/prepped_data_workspaceblobstore.\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/wd/prepped_data_workspaceblobstore.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-06-26T22:05:09.566387] Removing absolute paths from host...\n",
            "[2021-06-26T22:05:09.566816] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-06-26T22:05:09.886168] Ran Sidecar release cmd.\n",
            "[2021-06-26T22:05:09.886463] Job release is complete\n",
            "\n",
            "StepRun(Prepare Data) Execution Summary\n",
            "========================================\n",
            "StepRun( Prepare Data ) Status: Finished\n",
            "{'runId': '715cb5ea-43a5-46ae-b91c-02fa0d9e9440', 'target': 'dp100cc', 'status': 'Completed', 'startTimeUtc': '2021-06-26T22:02:34.176879Z', 'endTimeUtc': '2021-06-26T22:05:25.316516Z', 'properties': {'ContentSnapshotId': 'aed25108-25f8-4cc4-8e36-acc274b7495a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '16a51b59-fd08-4b55-aa12-9145410ab855', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '28b2524c', 'azureml.pipelinerunid': 'f3abba4d-ed34-46c7-af13-b138ff1ae88b', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '65b8a486-3be0-4a2e-9489-df54685f0c78'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '36fb13e5-160e-4877-b3a9-5164a220e037'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n",
            "  \"source\": [\n",
            "    \"('workspaceblobstore', 'dataset/715cb5ea-43a5-46ae-b91c-02fa0d9e9440/prepped_data/')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"36fb13e5-160e-4877-b3a9-5164a220e037\",\n",
            "    \"name\": null,\n",
            "    \"version\": null,\n",
            "    \"workspace\": \"Workspace.create(name='dp100ws', subscription_id='d1cbef34-81e9-4f99-9cf3-8d36f1255e04', resource_group='dp100')\"\n",
            "  }\n",
            "}}], 'runDefinition': {'script': 'prep_data.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'dp100cc', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '65b8a486-3be0-4a2e-9489-df54685f0c78', 'name': None, 'version': '3'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210513.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/azureml-logs/55_azureml-execution-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt?sv=2019-02-02&sr=b&sig=1a7E9%2B0VSC66VlraKr%2FO68h3%2BV2ZDik1A8lz1qC4Fjk%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'azureml-logs/65_job_prep-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/azureml-logs/65_job_prep-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt?sv=2019-02-02&sr=b&sig=iSkjuaBkX9VYpJzUvTvsXGI1OCmD%2BvNlrgDW6eHTNo8%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Y36TFM3QwR8hx%2Bwn8UFRJxgb%2FJCcSFcluvWOp%2B%2BORDI%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'azureml-logs/75_job_post-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/azureml-logs/75_job_post-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt?sv=2019-02-02&sr=b&sig=2UIw21%2FfU8XG92JaLUa9CwZ%2FysJzkwFCc3qHYyFpM9k%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'azureml-logs/process_info.json': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=5nyvWHAyTb5NlWxyswisDbnvxaTEj7tDQzpzJIFP3EQ%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'azureml-logs/process_status.json': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=AqTnmZm2cBRPLfhyaHU1CmDeQHxLA7Tha%2FX5I%2B1doUU%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/74_azureml.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/74_azureml.log?sv=2019-02-02&sr=b&sig=WGmH8qxJprFyEUp0KyQ4fn5mHyh8q4s0kWXwRR0cKLY%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=Eyb%2FkkyEM5ARQR7dX51Myhax%2B6MeCohNFDOKVuUiZ58%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=rfmGj5WsDBgH8OXyAXveV8OCNmrj8HcACX0dabBxT5k%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=WNQzHAVor9G8wGn%2BXB6wAQDLRBWN9fNMF1P8Mm2bLpU%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=BB3A3hYaVyxfvvkXf5%2BWhcFTJbBSbLk7%2BvEFPi0Jk7Y%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=40wpPBuWTT6%2BiFF1c40TWT0CFEmTyWvQ0msWatwy3H8%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/all.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/all.log?sv=2019-02-02&sr=b&sig=qgK17%2FtHGs0saCldJ0fPyNcKr76pGc0hRwxcghaFgjU%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.enter_contexts.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=AXWIX9c9BoxM0unC7v6NxsKwFzKGFVkikK0s3b1K8r0%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.exit_contexts.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=ZyJ3TbyrXtNyCJnRyu2KwU7jtcxNrUWyx%2BpVg7mtZ4Y%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=V5lYW%2FNcDw83XzRJR5nCijIv6jQrAbGwe52uDPnC2sA%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.715cb5ea-43a5-46ae-b91c-02fa0d9e9440/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=viLzrKudO5IUxHfI%2B5n9gCkh4qXeqzjLe6X0anfjufA%3D&st=2021-06-26T21%3A55%3A12Z&se=2021-06-27T06%3A05%3A12Z&sp=r'}, 'submittedBy': 'Daniel Cristian Fat'}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "StepRunId: f1454c10-0829-445d-aa3e-5d6011809dd0\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f1454c10-0829-445d-aa3e-5d6011809dd0?wsid=/subscriptions/d1cbef34-81e9-4f99-9cf3-8d36f1255e04/resourcegroups/dp100/workspaces/dp100ws&tid=37219092-bab7-4671-af41-d7ded0486bc7\n",
            "StepRun( Train and Register Model ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt\n",
            "========================================================================================================================\n",
            "2021-06-26T22:05:37Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=20363 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            "2021-06-26T22:05:37Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/mounts/workspaceblobstore\n",
            "2021-06-26T22:05:37Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
            "2021-06-26T22:05:37Z Starting output-watcher...\n",
            "2021-06-26T22:05:37Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2021-06-26T22:05:37Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
            "2021-06-26T22:05:37Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_fe4afc798de401edfb76dc27a38b1703\n",
            "Digest: sha256:5224cd9c4e07c9304c90193ab084da3cf8643e81065eef4d81c2c4029c58248c\n",
            "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_fe4afc798de401edfb76dc27a38b1703:latest\n",
            "viennaglobal.azurecr.io/azureml/azureml_fe4afc798de401edfb76dc27a38b1703:latest\n",
            "2021-06-26T22:05:38Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
            "2021-06-26T22:05:38Z Check if container f1454c10-0829-445d-aa3e-5d6011809dd0_DataSidecar already exist exited with 0, \n",
            "\n",
            "9e37cb12e849f46257936372aed74619a3041073845d314080acaf6b73f56c82\n",
            "2021-06-26T22:05:38Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            "2021-06-26T22:05:38Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-91c6e4c30d7a3554374dce6aa0726588-8e0509f819299d49-01 -sshRequired=false] \n",
            "2021/06/26 22:05:38 Starting App Insight Logger for task:  containerSetup\n",
            "2021/06/26 22:05:38 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
            "2021/06/26 22:05:38 Entered ContainerSetupTask - Preparing infiniband\n",
            "2021/06/26 22:05:38 Starting infiniband setup\n",
            "2021/06/26 22:05:38 Python Version found is Python 3.7.9\n",
            "\n",
            "2021/06/26 22:05:38 Returning Python Version as 3.7\n",
            "2021-06-26T22:05:38Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
            "2021/06/26 22:05:38 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
            "2021/06/26 22:05:38 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
            "2021/06/26 22:05:38 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021-06-26T22:05:38Z Not setting up Infiniband in Container\n",
            "2021/06/26 22:05:38 Not setting up Infiniband in Container\n",
            "2021/06/26 22:05:38 Not setting up Infiniband in Container\n",
            "2021/06/26 22:05:38 Python Version found is Python 3.7.9\n",
            "\n",
            "2021/06/26 22:05:38 Returning Python Version as 3.7\n",
            "2021/06/26 22:05:38 sshd inside container not required for job, skipping setup.\n",
            "2021/06/26 22:05:39 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
            "2021/06/26 22:05:39 App Insight Client has already been closed\n",
            "2021/06/26 22:05:39 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2021-06-26T22:05:39Z Starting docker container succeeded.\n",
            "2021-06-26T22:05:53Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
            "2021-06-26T22:05:53Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt\n",
            "===============================================================================================================\n",
            "[2021-06-26T22:06:02.980335] Entering job release\n",
            "[2021-06-26T22:06:03.818517] Starting job release\n",
            "[2021-06-26T22:06:03.819013] Logging experiment finalizing status in history service.\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 234\n",
            "[2021-06-26T22:06:03.819950] job release stage : upload_datastore starting...\n",
            "[2021-06-26T22:06:03.825578] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "[2021-06-26T22:06:03.834486] job release stage : execute_job_release starting...[2021-06-26T22:06:03.834848] job release stage : copy_batchai_cached_logs starting...\n",
            "\n",
            "[2021-06-26T22:06:03.835696] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-06-26T22:06:03.838334] Entering context manager injector.\n",
            "[2021-06-26T22:06:03.841259] job release stage : upload_datastore completed...\n",
            "[2021-06-26T22:06:03.910215] job release stage : send_run_telemetry starting...\n",
            "[2021-06-26T22:06:03.922539] get vm size and vm region successfully.\n",
            "[2021-06-26T22:06:03.929549] get compute meta data successfully.\n",
            "[2021-06-26T22:06:03.962463] job release stage : execute_job_release completed...\n",
            "[2021-06-26T22:06:04.080218] post artifact meta request successfully.\n",
            "[2021-06-26T22:06:04.107441] upload compute record artifact successfully.\n",
            "[2021-06-26T22:06:04.107610] job release stage : send_run_telemetry completed...\n",
            "[2021-06-26T22:06:04.108010] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-06-26T22:06:04.108352] Running Sidecar release cmd...\n",
            "[2021-06-26T22:06:04.129262] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/wd/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/wd/input_22a0f976_36fb13e5-160e-4877-b3a9-5164a220e037.\n",
            "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/wd/input_22a0f976_36fb13e5-160e-4877-b3a9-5164a220e037: Invalid argument\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp100ws/azureml/f1454c10-0829-445d-aa3e-5d6011809dd0/wd/input_22a0f976_36fb13e5-160e-4877-b3a9-5164a220e037.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-06-26T22:06:04.168563] Removing absolute paths from host...\n",
            "[2021-06-26T22:06:04.168783] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-06-26T22:06:05.033688] Ran Sidecar release cmd.\n",
            "[2021-06-26T22:06:05.033789] Job release is complete\n",
            "\n",
            "StepRun(Train and Register Model) Execution Summary\n",
            "====================================================\n",
            "StepRun( Train and Register Model ) Status: Finished\n",
            "{'runId': 'f1454c10-0829-445d-aa3e-5d6011809dd0', 'target': 'dp100cc', 'status': 'Completed', 'startTimeUtc': '2021-06-26T22:05:38.180853Z', 'endTimeUtc': '2021-06-26T22:06:13.999052Z', 'properties': {'ContentSnapshotId': 'aed25108-25f8-4cc4-8e36-acc274b7495a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '118b1f4d-5c32-457e-abfa-959035e7aec6', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '5a16bbd6', 'azureml.pipelinerunid': 'f3abba4d-ed34-46c7-af13-b138ff1ae88b', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '36fb13e5-160e-4877-b3a9-5164a220e037'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_22a0f976', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_model.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-data', 'DatasetConsumptionConfig:input_22a0f976'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'dp100cc', 'dataReferences': {}, 'data': {'input_22a0f976': {'dataLocation': {'dataset': {'id': '36fb13e5-160e-4877-b3a9-5164a220e037', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_22a0f976', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210513.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/azureml-logs/55_azureml-execution-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt?sv=2019-02-02&sr=b&sig=De%2BDqlTetcrrSVjdQCrJvinClEZsaMFYrKbFFg91X%2Fk%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'azureml-logs/65_job_prep-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/azureml-logs/65_job_prep-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt?sv=2019-02-02&sr=b&sig=dIMAukIAtMFFhye9QA%2BjXMXAez2uaTudnjt%2F8xkijR0%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Eq3PLX3xjdas3OK0LvRfTRhfi32POEMlg0cpQKnyNj0%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'azureml-logs/75_job_post-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/azureml-logs/75_job_post-tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d.txt?sv=2019-02-02&sr=b&sig=jknlkUq3P0pX8s5LgJ%2FYszKK%2FobKcdGFvznor9bo18Q%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'azureml-logs/process_info.json': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=gBFW79s%2Fn011Ii1Xayte8cms1Ro2O0jxQV7%2FTomQTFA%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'azureml-logs/process_status.json': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=9N6vOgNuDpD%2Fafdj2xJqw%2F83hU5ab2%2F18NcVMASCi6w%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/70_azureml.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/70_azureml.log?sv=2019-02-02&sr=b&sig=75uRZcAel7nj10N5OO2mPq7qBi7lfBW27Aue9ee2Xcg%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=eAXDVv%2B29Sl2XWK%2BH77ESrgoBuRn1aqggbrdbI%2FA01M%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=DDzJGW7COL0o8SOrWU3wB%2F8rALFX1liJIgZRCvDniDs%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=54%2Bw2RHRA5A9UCQqS8tmu79bqpvcHolYd35d7xMchiA%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=pGFA4LfaYCfrEw9zxl0Ae%2BOvTH2lqwrxGDvVLL3Sr5M%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=ldnLgdXQIX0CSaZg9wnIss2Ff98Ua6hKuGWW7Ezinvw%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/all.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/all.log?sv=2019-02-02&sr=b&sig=uh8pjfHTkmWbsi%2Fjlb3ynbTI13cAT0X8Cc%2BMC2NiT%2Bc%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.enter_contexts.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=ioeuo4THJeyZNYqeG2e0iW5Qk2hU2bIsCq7ntv98V0g%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.exit_contexts.log': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/sidecar/tvmps_dc8ea1a209373cc114cd479b7048bc51bc6824226f418b47bc28290d1087ceda_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=Sjq3dugiqFyqDXMq7op3Yr3lONgLHPilhA%2BMz1yH6jk%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=6saohLI0TxCu6cXqdPPK92DRvQWSniB8b3A33vPKyP0%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f1454c10-0829-445d-aa3e-5d6011809dd0/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=nPGLZUXItcydasMP3Ovs7FsV083FCTJ7gruVFznPNto%3D&st=2021-06-26T21%3A56%3A07Z&se=2021-06-27T06%3A06%3A07Z&sp=r'}, 'submittedBy': 'Daniel Cristian Fat'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': 'f3abba4d-ed34-46c7-af13-b138ff1ae88b', 'status': 'Completed', 'startTimeUtc': '2021-06-26T21:59:24.119996Z', 'endTimeUtc': '2021-06-26T22:06:15.119163Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f3abba4d-ed34-46c7-af13-b138ff1ae88b/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=CV8BLJS1pbR1H%2BkZ9ZWw7bPLLIca%2Bl%2Fb%2Fcm2CwyZ9lg%3D&st=2021-06-26T21%3A49%3A45Z&se=2021-06-27T05%3A59%3A45Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f3abba4d-ed34-46c7-af13-b138ff1ae88b/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=cyYyOOLp7eGvJiXN5MXx8DO0TBaUsEqy4ZyPhywoHxE%3D&st=2021-06-26T21%3A49%3A45Z&se=2021-06-27T05%3A59%3A45Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp100ws2635569048.blob.core.windows.net/azureml/ExperimentRun/dcid.f3abba4d-ed34-46c7-af13-b138ff1ae88b/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=GH2nelx01fTK20iV5lDUNAYdJeuCn7NB3pmrwhzrru4%3D&st=2021-06-26T21%3A49%3A45Z&se=2021-06-27T05%3A59%3A45Z&sp=r'}, 'submittedBy': 'Daniel Cristian Fat'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 133,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 133,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624745176747
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline run outputs and metrics**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Register Model :\n",
            "\t RMSE : 4527.777539508901\n",
            "Prepare Data :\n",
            "\t raw_rows : 10302\n",
            "\t processed_rows : 8092\n"
          ]
        }
      ],
      "execution_count": 134,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624745178123
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get latest registered model**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['auto_claims_zip_model']\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auto_claims_zip_model version 5\n"
          ]
        }
      ],
      "execution_count": 135,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624745179050
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create prediction functions for the service**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $service_folder/score_auto_claims.py\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from azureml.core.model import Model\n",
        "from preprocessing import preprocessing\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = Model.get_model_path('auto_claims_zip_model')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # Get a prediction from the model\n",
        "    data = preprocessing(data,inference=True).dropna()\n",
        "\n",
        "    def predict(models,data):\n",
        "        out = dict(\n",
        "            lr_pred = models['lr_model'].predict_proba(data)[:,1],\n",
        "            po_pred = models['po_model'].predict(data),\n",
        "            gm_pred = models['gm_model'].predict(data)\n",
        "        )\n",
        "        out['loss_cost'] = (out['lr_pred'] * out['po_pred']) * out['gm_pred']\n",
        "\n",
        "        for k in out.keys():\n",
        "            out[k] = out[k].tolist()\n",
        "            \n",
        "        return out\n",
        "\n",
        "    predictions = predict(model,data)\n",
        "\n",
        "    return json.dumps(predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting auto_claims_service/score_auto_claims.py\n"
          ]
        }
      ],
      "execution_count": 151,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create conda environment file for the service**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $service_folder/auto_claims_env.yml\n",
        "name: inference_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting auto_claims_service/auto_claims_env.yml\n"
          ]
        }
      ],
      "execution_count": 152,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure and Deploy Service**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core import Model\n",
        "# Configure the scoring environment\n",
        "inference_config = InferenceConfig(\n",
        "                                   source_directory=service_folder,\n",
        "                                   runtime='python',\n",
        "                                   entry_script='score_auto_claims.py',\n",
        "                                   conda_file='auto_claims_env.yml')\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "\n",
        "service_name = \"auto-claims-service\"\n",
        "\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
        "\n",
        "service.wait_for_deployment(True)\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-06-26 22:10:47+00:00 Creating Container Registry if not exists.\n",
            "2021-06-26 22:10:47+00:00 Registering the environment.\n",
            "2021-06-26 22:10:48+00:00 Use the existing image.\n",
            "2021-06-26 22:10:48+00:00 Generating deployment configuration.\n",
            "2021-06-26 22:10:49+00:00 Submitting deployment to compute.\n",
            "2021-06-26 22:10:53+00:00 Checking the status of deployment auto-claims-service..\n",
            "2021-06-26 22:13:23+00:00 Checking the status of inference endpoint auto-claims-service.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "execution_count": 153,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624745604325
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Take a random sample from the initial data and run it through the service**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = df[df.columns[~df.columns.isin(['CLM_AMT','CLAIM_FLAG','CLM_FREQ'])]].sample(5)\n",
        "endpoint_url = service.scoring_uri\n",
        "print('Endpoint:',endpoint_url)\n",
        "input_json = json.dumps({\"data\": sample_data.values.tolist()})\n",
        "\n",
        "# Set the content type\n",
        "headers = { 'Content-Type':'application/json' }\n",
        "\n",
        "response = requests.post(endpoint_url, input_json, headers = headers)\n",
        "if response.status_code == 200:\n",
        "    preds = pd.read_json(response.json())\n",
        "    sample_pred = sample_data.copy().reset_index(drop=True)\n",
        "    sample_pred[preds.columns.tolist()] = preds\n",
        "    print(sample_pred)\n",
        "else:\n",
        "    print(response.text,response.status_code)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoint: http://e76a45a3-317c-4859-ac97-bd750939bb38.centralus.azurecontainer.io/score\n",
            "          ID KIDSDRIV    BIRTH AGE HOMEKIDS   YOJ    INCOME PARENT1  HOME_VAL  \\\n",
            "0  695733470        0  02MAY57  42        2  None   $80,054     Yes        $0   \n",
            "1  563884496        0  01OCT66  33        2    14   $36,351      No  $193,200   \n",
            "2  711084452        0  24JUN54  45        2     9      None     Yes        $0   \n",
            "3   57346072        0  13MAY57  42        0    10  $101,636      No        $0   \n",
            "4  356077226        0  21NOV55  43        0    11   $75,232      No        $0   \n",
            "\n",
            "  MSTATUS  ... RED_CAR OLDCLAIM REVOKED MVR_PTS CAR_AGE  \\\n",
            "0    z_No  ...      no       $0      No       1      10   \n",
            "1     Yes  ...     yes   $3,647      No       3      13   \n",
            "2    z_No  ...     yes   $1,055      No       1       1   \n",
            "3    z_No  ...      no   $1,452      No       7      11   \n",
            "4    z_No  ...     yes       $0      No       5       7   \n",
            "\n",
            "              URBANICITY   lr_pred   po_pred      gm_pred    loss_cost  \n",
            "0  z_Highly Rural/ Rural  0.054343  0.146928  5478.038619    43.739267  \n",
            "1    Highly Urban/ Urban  0.434083  1.715058  5223.355332  3888.673951  \n",
            "2    Highly Urban/ Urban  0.233435  0.167620  6078.339690   237.836231  \n",
            "3    Highly Urban/ Urban       NaN       NaN          NaN          NaN  \n",
            "4    Highly Urban/ Urban       NaN       NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ],
      "execution_count": 155,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624745631265
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Service**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": 156,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624746190901
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}